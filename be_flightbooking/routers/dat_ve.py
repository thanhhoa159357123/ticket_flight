from fastapi import APIRouter, HTTPException, Query
from fastapi.responses import JSONResponse
from models.datve import DatVe
from pyspark.sql import functions as F
from pyspark.sql.functions import from_json, explode, col, when, array
from pyspark.sql.types import ArrayType, StringType
from utils.spark import load_df, invalidate_cache
from utils.env_loader import MONGO_DB, MONGO_URI
from pymongo import MongoClient
from datetime import datetime, date
import uuid
import json

router = APIRouter()
client = MongoClient(MONGO_URI)
db = client[MONGO_DB]
dat_ve_collection = db["datve"]


@router.post("", tags=["datve"])
def add_dat_ve(dat_ve: DatVe):
    try:

        print(f"Nh·∫≠n y√™u c·∫ßu POST /add: {dat_ve.ma_dat_ve}")
        print("üöÄ D·ªØ li·ªáu nh·∫≠n ƒë∆∞·ª£c t·ª´ client:", dat_ve.dict())

        df_dat_ve = load_df("datve")
        df_khach_hang = load_df("khachhang")
        df_hang_ve = load_df("hangve")
        df_chuyen_bay = load_df("chuyenbay")

        # ‚úÖ Ki·ªÉm tra m√£ kh√°ch h√†ng
        if (
            df_khach_hang.filter(
                df_khach_hang.ma_khach_hang == dat_ve.ma_khach_hang
            ).count()
            == 0
        ):
            raise HTTPException(status_code=400, detail="M√£ kh√°ch h√†ng kh√¥ng t·ªìn t·∫°i")

        # üëâ Chu·∫©n h√≥a v·ªÅ d·∫°ng list
        ma_chuyen_bay_list = (
            dat_ve.ma_chuyen_bay
            if isinstance(dat_ve.ma_chuyen_bay, list)
            else [dat_ve.ma_chuyen_bay]
        )
        ma_hang_ve_list = (
            dat_ve.ma_hang_ve
            if isinstance(dat_ve.ma_hang_ve, list)
            else [dat_ve.ma_hang_ve]
        )

        # ‚úÖ Validation m√£ chuy·∫øn bay
        for ma_cb in ma_chuyen_bay_list:
            if df_chuyen_bay.filter(df_chuyen_bay.ma_chuyen_bay == ma_cb).count() == 0:
                raise HTTPException(
                    status_code=400, detail=f"M√£ chuy·∫øn bay kh√¥ng t·ªìn t·∫°i: {ma_cb}"
                )

        # ‚úÖ Validation m√£ h·∫°ng v√©
        for ma_hv in ma_hang_ve_list:
            if df_hang_ve.filter(df_hang_ve.ma_hang_ve == ma_hv).count() == 0:
                raise HTTPException(
                    status_code=400, detail=f"M√£ h·∫°ng v√© kh√¥ng t·ªìn t·∫°i: {ma_hv}"
                )

        # üÜï Sinh m√£ ƒë·∫∑t v√© n·∫øu ch∆∞a c√≥
        ma_dat_ve = dat_ve.ma_dat_ve or f"DV{uuid.uuid4().hex[:8].upper()}"

        # üí° Ki·ªÉm tra tr√πng m√£
        if "ma_dat_ve" in df_dat_ve.columns:
            if df_dat_ve.filter(df_dat_ve["ma_dat_ve"] == ma_dat_ve).count() > 0:
                raise HTTPException(status_code=400, detail="M√£ ƒë·∫∑t v√© ƒë√£ t·ªìn t·∫°i")

        # üîÑ Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ insert
        data_to_insert = dat_ve.dict()
        data_to_insert["ma_dat_ve"] = ma_dat_ve

        # X·ª≠ l√Ω datetime
        if isinstance(data_to_insert["ngay_dat"], date):
            data_to_insert["ngay_dat"] = datetime.combine(
                data_to_insert["ngay_dat"], datetime.min.time()
            )

        # üì• Ghi v√†o MongoDB
        insert_result = dat_ve_collection.insert_one(data_to_insert)
        invalidate_cache("datve")

        # ‚úÖ Chu·∫©n b·ªã d·ªØ li·ªáu tr·∫£ v·ªÅ
        data_to_insert["_id"] = str(insert_result.inserted_id)
        data_to_insert["ngay_dat"] = data_to_insert["ngay_dat"].isoformat()

        print("‚úÖ ƒê·∫∑t v√© th√†nh c√¥ng:", ma_dat_ve)
        return JSONResponse(
            content={"message": "Th√™m ƒë·∫∑t v√© th√†nh c√¥ng", "datve": data_to_insert}
        )

    except HTTPException as he:
        raise he
    except Exception as e:
        print("‚ùå L·ªói:", e)
        raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


@router.get("", tags=["dat_ve"])
def get_existing_dat_ve(
    ma_khach_hang: str = Query(...),
    loai_chuyen_di: str = Query(None),  # Optional cho new format
):
    try:
        # ‚úÖ T√¨m ki·∫øm linh ho·∫°t - ∆∞u ti√™n fields m·ªõi
        search_criteria = {"ma_khach_hang": ma_khach_hang}

        if loai_chuyen_di:
            search_criteria["loai_chuyen_di"] = loai_chuyen_di

        result = dat_ve_collection.find_one(
            search_criteria,
            sort=[("ngay_dat", -1)],  # ∆Øu ti√™n b·∫£n ghi g·∫ßn nh·∫•t
        )

        if not result:
            raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y b·∫£n ghi ƒë·∫∑t v√©")

        return {
            "ma_dat_ve": result["ma_dat_ve"],
            "dat_ve": {
                "ma_khach_hang": result["ma_khach_hang"],
                "loai_chuyen_di": result.get("loai_chuyen_di", "M·ªôt chi·ªÅu"),
                "ma_chuyen_di": result.get("ma_chuyen_di"),  # Backward compatibility
                "ngay_dat": (
                    result["ngay_dat"].isoformat()
                    if isinstance(result["ngay_dat"], datetime)
                    else result["ngay_dat"]
                ),
                "ma_dat_ve": result["ma_dat_ve"],
                "ma_hang_ve_di": result.get("ma_hang_ve_di"),
                "ma_chuyen_bay_di": result.get("ma_chuyen_bay_di"),
                "ma_hang_ve_ve": result.get("ma_hang_ve_ve"),
                "ma_chuyen_bay_ve": result.get("ma_chuyen_bay_ve"),
                "trang_thai": result.get("trang_thai", "ƒêang x·ª≠ l√Ω"),
            },
        }

    except HTTPException as he:
        raise he
    except Exception as e:
        print("‚ùå L·ªói get_existing_dat_ve:", e)
        raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


@router.get("/all", tags=["dat_ve"])
def get_all_dat_ve_by_user(ma_khach_hang: str = Query(...)):
    try:
        spark = load_df("datve").sparkSession

        # 1Ô∏è‚É£ Load c√°c b·∫£ng li√™n quan
        df_datve = load_df("datve")
        df_chitiet = load_df("chitietdatve")
        df_ve = load_df("ve")
        df_hangve = load_df("hangve")
        df_cb = load_df("chuyenbay")
        df_sb = load_df("sanbay")
        df_hk = load_df("hanhkhach")

        # 2Ô∏è‚É£ Explode ma_ve n·∫øu c·∫ßn
        if dict(df_chitiet.dtypes)["ma_ve"] != "array<string>":
            df_chitiet = df_chitiet.withColumn(
                "ma_ve_array",
                when(
                    col("ma_ve").startswith("["),
                    from_json("ma_ve", ArrayType(StringType())),
                ).otherwise(F.array("ma_ve")),
            )
            df_chitiet = df_chitiet.withColumn("ma_ve", explode("ma_ve_array")).drop(
                "ma_ve_array"
            )
        else:
            df_chitiet = df_chitiet.withColumn("ma_ve", explode("ma_ve"))

        # 3Ô∏è‚É£ Explode ma_hanh_khach n·∫øu n√≥ l√† array
        if dict(df_chitiet.dtypes)["ma_hanh_khach"] == "array<string>":
            df_chitiet = df_chitiet.withColumn(
                "ma_hanh_khach", explode("ma_hanh_khach")
            )

        # 4Ô∏è‚É£ T·∫°o view cho Spark SQL
        df_datve.createOrReplaceTempView("datve")
        df_chitiet.createOrReplaceTempView("chitietdatve")
        df_ve.createOrReplaceTempView("ve")
        df_hangve.createOrReplaceTempView("hangve")
        df_cb.createOrReplaceTempView("chuyenbay")
        df_sb.createOrReplaceTempView("sanbay")
        df_hk.createOrReplaceTempView("hanhkhach")

        # 5Ô∏è‚É£ Truy v·∫•n chi ti·∫øt v√© + h√†nh kh√°ch
        query = f"""
        SELECT
            dv.ma_dat_ve,
            dv.ngay_dat,
            dv.trang_thai,
            dv.loai_chuyen_di,
            dv.ma_khach_hang,
            ctdv.ma_ve,
            ctdv.ma_hanh_khach,
            hk.danh_xung,
            hk.ho_hanh_khach,
            hk.ten_hanh_khach,
            hk.ngay_sinh,
            v.ma_chuyen_bay,
            v.ma_hang_ve,
            hv.ten_hang_ve,
            cb.thoi_gian_di,
            cb.thoi_gian_den,
            sb_di.ten_san_bay AS ten_san_bay_di,
            sb_den.ten_san_bay AS ten_san_bay_den
        FROM datve dv
        LEFT JOIN chitietdatve ctdv ON dv.ma_dat_ve = ctdv.ma_dat_ve
        LEFT JOIN ve v ON ctdv.ma_ve = v.ma_ve
        LEFT JOIN hangve hv ON v.ma_hang_ve = hv.ma_hang_ve
        LEFT JOIN chuyenbay cb ON v.ma_chuyen_bay = cb.ma_chuyen_bay
        LEFT JOIN sanbay sb_di ON cb.ma_san_bay_di = sb_di.ma_san_bay
        LEFT JOIN sanbay sb_den ON cb.ma_san_bay_den = sb_den.ma_san_bay
        LEFT JOIN hanhkhach hk ON ctdv.ma_hanh_khach = hk.ma_hanh_khach
        WHERE dv.ma_khach_hang = '{ma_khach_hang}'
        """
        df = spark.sql(query)

        # 6Ô∏è‚É£ Gom h√†nh kh√°ch theo t·ª´ng v√©
        df_grouped_ve = df.groupBy(
            "ma_dat_ve",
            "ma_khach_hang",
            "ma_ve",
            "ma_chuyen_bay",
            "ma_hang_ve",
            "ten_hang_ve",
            "thoi_gian_di",
            "thoi_gian_den",
            "ten_san_bay_di",
            "ten_san_bay_den",
        ).agg(
            F.collect_list(
                F.struct(
                    "ma_hanh_khach",
                    "danh_xung",
                    "ho_hanh_khach",
                    "ten_hanh_khach",
                    "ngay_sinh",
                )
            ).alias("danh_sach_hanh_khach")
        )

        # 7Ô∏è‚É£ Gom v√© theo ƒë∆°n ƒë·∫∑t v√©, gi·ªØ ma_khach_hang ƒë·ªÉ tr√°nh nh·∫ßm kh√°ch
        df_grouped_datve = df_grouped_ve.groupBy("ma_dat_ve", "ma_khach_hang").agg(
            F.collect_list(
                F.struct(
                    "ma_ve",
                    "ma_chuyen_bay",
                    "ma_hang_ve",
                    "ten_hang_ve",
                    "thoi_gian_di",
                    "thoi_gian_den",
                    "ten_san_bay_di",
                    "ten_san_bay_den",
                    "danh_sach_hanh_khach",
                )
            ).alias("chi_tiet_ve_dat")
        )

        # 8Ô∏è‚É£ Join l·∫°i v·ªõi df_datve ƒë√£ l·ªçc ma_khach_hang
        df_datve_filtered = df_datve.filter(col("ma_khach_hang") == ma_khach_hang)
        final_df = df_datve_filtered.join(
            df_grouped_datve, on="ma_dat_ve", how="left"
        ).orderBy(F.col("ngay_dat").desc())

        invalidate_cache("datve")
        
        # 9Ô∏è‚É£ Tr·∫£ d·ªØ li·ªáu JSON v·ªÅ FE
        return [json.loads(row) for row in final_df.toJSON().collect()]

    except Exception as e:
        print("‚ùå L·ªói Spark SQL:", e)
        raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


# @router.delete("/delete-all", tags=["dat_ve"])
# def delete_all_dat_ve():
#     """X√≥a t·∫•t c·∫£ d·ªØ li·ªáu ƒë·∫∑t v√© - CH·ªà D√ôNG ƒê·ªÇ TEST"""
#     try:
#         # X√≥a t·∫•t c·∫£ records trong collection dat_ve
#         result = dat_ve_collection.delete_many({})

#         # Invalidate cache
#         refresh_cache("dat_ve")

#         print(f"üóëÔ∏è ƒê√£ x√≥a t·∫•t c·∫£ {result.deleted_count} records ƒë·∫∑t v√©")
#         return JSONResponse(
#             content={
#                 "message": f"ƒê√£ x√≥a t·∫•t c·∫£ d·ªØ li·ªáu ƒë·∫∑t v√© th√†nh c√¥ng",
#                 "deleted_count": result.deleted_count,
#             }
#         )

#     except Exception as e:
#         print("‚ùå L·ªói khi x√≥a t·∫•t c·∫£ ƒë·∫∑t v√©:", e)
#         raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


# ‚úÖ Hybrid approach: D√πng Spark ƒë·ªÉ validate + MongoDB ƒë·ªÉ update
@router.patch("/{ma_dat_ve}/refund", tags=["dat_ve"])
def request_refund_ticket_hybrid(ma_dat_ve: str):
    try:
        # Load c√°c DataFrame c·∫ßn thi·∫øt
        df_datve = load_df("datve")
        df_ctdv = load_df("chitietdatve")
        df_ve = load_df("ve")
        df_hangve = load_df("hangve")

        # ‚úÖ Fix l·ªói array<string> b·∫±ng explode tr∆∞·ªõc khi join
        if dict(df_ctdv.dtypes)["ma_ve"] == "array<string>":
            df_ctdv = df_ctdv.withColumn("ma_ve", F.explode("ma_ve"))

        # T·∫°o view cho Spark SQL
        df_datve.createOrReplaceTempView("datve")
        df_ctdv.createOrReplaceTempView("chitietdatve")
        df_ve.createOrReplaceTempView("ve")
        df_hangve.createOrReplaceTempView("hangve")

        # Query v√©
        query = f"""
        SELECT dv.ma_dat_ve, dv.trang_thai, dv.ma_khach_hang,
               v.ma_hang_ve, hv.ten_hang_ve, hv.refundable, v.gia_ve
        FROM datve dv
        LEFT JOIN chitietdatve ctdv ON dv.ma_dat_ve = ctdv.ma_dat_ve
        LEFT JOIN ve v ON ctdv.ma_ve = v.ma_ve
        LEFT JOIN hangve hv ON v.ma_hang_ve = hv.ma_hang_ve
        WHERE dv.ma_dat_ve = '{ma_dat_ve}'
        """

        spark = df_datve.sparkSession
        results = spark.sql(query).collect()

        if not results:
            raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y m√£ ƒë·∫∑t v√©")

        ticket_info = results[0]

        # Ki·ªÉm tra tr·∫°ng th√°i v√©
        if ticket_info["trang_thai"] != "ƒê√£ thanh to√°n":
            raise HTTPException(
                status_code=400,
                detail=f"Ch·ªâ ho√†n v√© ƒë√£ thanh to√°n. Tr·∫°ng th√°i hi·ªán t·∫°i: {ticket_info['trang_thai']}",
            )

        # Ki·ªÉm tra ƒëi·ªÅu ki·ªán ho√†n v√©
        if ticket_info["refundable"] is not None and not ticket_info["refundable"]:
            raise HTTPException(
                status_code=400,
                detail=f"H·∫°ng v√© {ticket_info['ten_hang_ve']} kh√¥ng ƒë∆∞·ª£c ph√©p ho√†n v√©",
            )

        # T√≠nh s·ªë ti·ªÅn ho√†n (90%)
        gia_ve_hoan = int(ticket_info["gia_ve"] * 0.9)

        # C·∫≠p nh·∫≠t tr·∫°ng th√°i trong MongoDB
        update_result = dat_ve_collection.update_one(
            {"ma_dat_ve": ma_dat_ve},
            {
                "$set": {
                    "trang_thai": "Ch·ªù duy·ªát ho√†n v√©",
                    "ngay_yeu_cau_hoan": datetime.now(),
                    "gia_ve_hoan": gia_ve_hoan,
                    "trang_thai_duyet": "Ch·ªù x·ª≠ l√Ω",
                    "admin_xem": False,
                }
            },
        )

        if update_result.modified_count == 0:
            raise HTTPException(status_code=400, detail="Kh√¥ng th·ªÉ c·∫≠p nh·∫≠t tr·∫°ng th√°i")

        invalidate_cache("datve")

        return JSONResponse(
            content={
                "message": "Y√™u c·∫ßu ho√†n v√© th√†nh c√¥ng",
                "ma_dat_ve": ma_dat_ve,
                "trang_thai_moi": "Ch·ªù duy·ªát ho√†n v√©",
                "so_tien_hoan": gia_ve_hoan,
            }
        )

    except HTTPException as he:
        raise he
    except Exception as e:
        print("‚ùå L·ªói hybrid refund request:", e)
        raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")



@router.patch("/{ma_dat_ve}/approve-refund", tags=["admin"])
def approve_refund(ma_dat_ve: str, approved: bool = Query(...)):
    try:
        # üîç T√¨m th√¥ng tin v√©
        ticket_doc = dat_ve_collection.find_one({"ma_dat_ve": ma_dat_ve})
        if not ticket_doc:
            raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y m√£ ƒë·∫∑t v√©")

        # üõë Ch·ªâ x·ª≠ l√Ω n·∫øu v√© ƒëang ch·ªù duy·ªát ho√†n v√©
        if ticket_doc.get("trang_thai") != "Ch·ªù duy·ªát ho√†n v√©":
            raise HTTPException(
                status_code=400,
                detail=f"V√© kh√¥ng ·ªü tr·∫°ng th√°i ch·ªù duy·ªát. Tr·∫°ng th√°i hi·ªán t·∫°i: {ticket_doc.get('trang_thai')}",
            )

        # ‚úÖ N·∫øu DUY·ªÜT
        if approved:
            new_status = "ƒê√£ ho√†n v√©"
            update_data = {
                "trang_thai": new_status,
                "trang_thai_duyet": "ƒê√£ duy·ªát",
                "ngay_duyet_hoan": datetime.now(),
                "ngay_hoan_ve": datetime.now(),
                "admin_duyet": "SYSTEM",
                "so_tien_hoan": ticket_doc.get("gia_ve_hoan", 1500000),
            }
        else:
            # ‚ùå N·∫øu T·ª™ CH·ªêI
            new_status = "ƒê√£ thanh to√°n"
            update_data = {
                "trang_thai": new_status,
                "trang_thai_duyet": "T·ª´ ch·ªëi",
                "ngay_duyet_hoan": datetime.now(),
                "admin_duyet": "SYSTEM",
                "ly_do_tu_choi": "Admin t·ª´ ch·ªëi y√™u c·∫ßu ho√†n v√©",
            }

        # üíæ Update v√©
        dat_ve_collection.update_one(
            {"ma_dat_ve": ma_dat_ve},
            {"$set": update_data}
        )

        # N·∫øu t·ª´ ch·ªëi th√¨ x√≥a field li√™n quan
        if not approved:
            dat_ve_collection.update_one(
                {"ma_dat_ve": ma_dat_ve},
                {
                    "$unset": {
                        "ngay_yeu_cau_hoan": "",
                        "gia_ve_hoan": "",
                        "nguoi_yeu_cau": "",
                        "admin_xem": "",
                    }
                }
            )

        # üîÑ Refresh Spark cache
        invalidate_cache("datve")

        return JSONResponse(
            content={
                "message": f"{'Duy·ªát' if approved else 'T·ª´ ch·ªëi'} ho√†n v√© th√†nh c√¥ng",
                "approved": approved,
                "new_status": new_status,
                "so_tien_hoan": update_data.get("so_tien_hoan", 0),
            }
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå L·ªói approve refund: {e}")
        raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")

# @router.get("", tags=["dat_ve"])
# def get_existing_dat_ve(
#     ma_khach_hang: str = Query(...),
#     loai_chuyen_di: str = Query(None),  # Optional cho new format
# ):
#     try:
#         # ‚úÖ T√¨m ki·∫øm linh ho·∫°t - ∆∞u ti√™n fields m·ªõi
#         search_criteria = {"ma_khach_hang": ma_khach_hang}

#         if loai_chuyen_di:
#             search_criteria["loai_chuyen_di"] = loai_chuyen_di

#         result = dat_ve_collection.find_one(
#             search_criteria,
#             sort=[("ngay_dat", -1)],  # ∆Øu ti√™n b·∫£n ghi g·∫ßn nh·∫•t
#         )

#         if not result:
#             raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y b·∫£n ghi ƒë·∫∑t v√©")

#         return {
#             "ma_dat_ve": result["ma_dat_ve"],
#             "dat_ve": {
#                 "ma_khach_hang": result["ma_khach_hang"],
#                 "loai_chuyen_di": result.get("loai_chuyen_di", "M·ªôt chi·ªÅu"),
#                 "ma_chuyen_di": result.get("ma_chuyen_di"),  # Backward compatibility
#                 "ngay_dat": (
#                     result["ngay_dat"].isoformat()
#                     if isinstance(result["ngay_dat"], datetime)
#                     else result["ngay_dat"]
#                 ),
#                 "ma_dat_ve": result["ma_dat_ve"],
#                 "ma_hang_ve_di": result.get("ma_hang_ve_di"),
#                 "ma_chuyen_bay_di": result.get("ma_chuyen_bay_di"),
#                 "ma_hang_ve_ve": result.get("ma_hang_ve_ve"),
#                 "ma_chuyen_bay_ve": result.get("ma_chuyen_bay_ve"),
#                 "trang_thai": result.get("trang_thai", "ƒêang x·ª≠ l√Ω"),
#             },
#         }

#     except HTTPException as he:
#         raise he
#     except Exception as e:
#         print("‚ùå L·ªói get_existing_dat_ve:", e)
#         raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


# @router.delete("/{ma_dat_ve}", tags=["dat_ve"])
# def cancel_dat_ve(ma_dat_ve: str):
#     try:
#         # T√¨m b·∫£n ghi ƒë·∫∑t v√©
#         result = dat_ve_collection.find_one({"ma_dat_ve": ma_dat_ve})
#         if not result:
#             raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y m√£ ƒë·∫∑t v√©")

#         # C·∫≠p nh·∫≠t tr·∫°ng th√°i sang "ƒê√£ h·ªßy"
#         update_result = dat_ve_collection.update_one(
#             {"ma_dat_ve": ma_dat_ve}, {"$set": {"trang_thai": "ƒê√£ h·ªßy"}}
#         )

#         if update_result.modified_count == 0:
#             raise HTTPException(status_code=400, detail="Kh√¥ng th·ªÉ c·∫≠p nh·∫≠t tr·∫°ng th√°i")

#         # Invalidate cache Spark
#         refresh_cache("dat_ve")

#         print(f"üö´ ƒê√£ c·∫≠p nh·∫≠t tr·∫°ng th√°i h·ªßy v√© cho m√£ {ma_dat_ve}")
#         return JSONResponse(content={"message": f"ƒê√£ h·ªßy v√© {ma_dat_ve} th√†nh c√¥ng"})

#     except HTTPException as he:
#         raise he
#     except Exception as e:
#         print("‚ùå L·ªói khi c·∫≠p nh·∫≠t tr·∫°ng th√°i h·ªßy v√©:", e)
#         raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")
