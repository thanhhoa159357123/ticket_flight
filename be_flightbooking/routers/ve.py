from fastapi import APIRouter, HTTPException, UploadFile, File
from fastapi.responses import JSONResponse
from pyspark import StorageLevel
from models.ve import Ve
from utils.spark import load_df, get_spark, invalidate_cache
from utils.env_loader import MONGO_DB, MONGO_URI
from pymongo import MongoClient
from pymongo.errors import DuplicateKeyError
from pydantic import BaseModel
from typing import List, Optional
import traceback
import pandas as pd
import io

router = APIRouter()
client = MongoClient(MONGO_URI)
ve_collection = client[MONGO_DB]["ve"]


def safe_escape_sql(value: str) -> str:
    return value.replace("'", "''").replace("\\", "\\\\")


def check_exists_optimized(collection_name: str, field_name: str, value: str) -> bool:
    try:
        df = load_df(collection_name)
        return df.filter(df[field_name] == value).limit(1).count() > 0
    except Exception as e:
        print(f"‚ùå L·ªói check_exists_optimized {collection_name}.{field_name}: {e}")
        return False


# Request models
class GiaVeRequest(BaseModel):
    ma_gia_ves: List[str]


@router.post("", tags=["ve"])
def add_ve(ve: Ve):
    try:
        if not ve.ma_ve.strip():
            raise HTTPException(status_code=400, detail="M√£ v√© kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng")
        if ve.gia_ve <= 0:
            raise HTTPException(status_code=400, detail="Gi√° v√© ph·∫£i l·ªõn h∆°n 0")
        if not ve.ma_hang_ve or not ve.ma_hang_ve.strip():
            raise HTTPException(
                status_code=400, detail="M√£ h·∫°ng v√© kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"
            )
        if not ve.ma_chuyen_bay or not ve.ma_chuyen_bay.strip():
            raise HTTPException(
                status_code=400, detail="M√£ chuy·∫øn bay kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"
            )
        if not ve.ma_hang_ban_ve or not ve.ma_hang_ban_ve.strip():
            raise HTTPException(
                status_code=400, detail="M√£ h√£ng b√°n v√© kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"
            )

        if check_exists_optimized("ve", "ma_ve", ve.ma_ve):
            raise HTTPException(status_code=400, detail="M√£ v√© ƒë√£ t·ªìn t·∫°i")

        validations = [
            (
                check_exists_optimized("hangve", "ma_hang_ve", ve.ma_hang_ve),
                "M√£ h·∫°ng v√© kh√¥ng t·ªìn t·∫°i",
            ),
            (
                check_exists_optimized("chuyenbay", "ma_chuyen_bay", ve.ma_chuyen_bay),
                "M√£ chuy·∫øn bay kh√¥ng t·ªìn t·∫°i",
            ),
            (
                check_exists_optimized(
                    "hangbanve", "ma_hang_ban_ve", ve.ma_hang_ban_ve
                ),
                "M√£ h√£ng b√°n v√© kh√¥ng t·ªìn t·∫°i",
            ),
        ]

        for is_valid, error_msg in validations:
            if not is_valid:
                raise HTTPException(status_code=400, detail=error_msg)

        data_to_insert = ve.dict()
        try:
            result = ve_collection.insert_one(data_to_insert)
            if not result.inserted_id:
                raise HTTPException(status_code=500, detail="Kh√¥ng th·ªÉ th√™m v√©")
        except DuplicateKeyError:
            raise HTTPException(status_code=400, detail="M√£ v√© ƒë√£ t·ªìn t·∫°i")

        # Refresh cache ƒë·ªÉ c√≥ d·ªØ li·ªáu m·ªõi ngay l·∫≠p t·ª©c
        invalidate_cache("ve")
        data_to_insert["_id"] = str(result.inserted_id)

        return JSONResponse(
            content={"message": "Th√™m v√© th√†nh c√¥ng", "ve": data_to_insert},
            status_code=201,
        )

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå L·ªói trong add_ve: {repr(e)}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


@router.get("", tags=["ve"])
def get_all_ve():
    try:
        spark = get_spark()
        spark.conf.set("spark.sql.execution.arrow.pyspark.fallback.enabled", "true")

        query = """
        SELECT /*+ BROADCAST(hv), BROADCAST(hbv), BROADCAST(hb), BROADCAST(sb_di), BROADCAST(sb_den) */
            v.ma_ve,
            v.gia_ve,
            v.ma_chuyen_bay,
            v.ma_hang_ve,
            v.ma_hang_ban_ve,
            CAST(cb.thoi_gian_di AS STRING) AS thoi_gian_di,
            CAST(cb.thoi_gian_den AS STRING) AS thoi_gian_den,
            cb.ma_hang_bay,
            cb.ma_san_bay_di,
            cb.ma_san_bay_den,
            sb_di.ten_san_bay AS ten_san_bay_di,
            sb_den.ten_san_bay AS ten_san_bay_den,
            sb_di.thanh_pho AS ten_thanh_pho_di,
            sb_den.thanh_pho AS ten_thanh_pho_den,
            hv.ten_hang_ve,
            hv.so_kg_hanh_ly_ky_gui,
            hv.so_kg_hanh_ly_xach_tay,
            hv.so_do_ghe,
            hv.khoang_cach_ghe,
            hv.refundable,
            hv.changeable,
            hbv.ten_hang_ban_ve,
            hbv.vai_tro,
            hb.ten_hang_bay,
            hb.iata_code as hang_bay_iata,
            hb.quoc_gia,
            CONCAT(sb_di.thanh_pho, ' ‚Üí ', sb_den.thanh_pho) AS route_display,
            CONCAT(hb.ten_hang_bay, ' - ', cb.ma_chuyen_bay) AS flight_display
        FROM ve v
        LEFT JOIN chuyenbay cb ON v.ma_chuyen_bay = cb.ma_chuyen_bay
        LEFT JOIN hangve hv ON v.ma_hang_ve = hv.ma_hang_ve
        LEFT JOIN hangbanve hbv ON v.ma_hang_ban_ve = hbv.ma_hang_ban_ve
        LEFT JOIN hangbay hb ON cb.ma_hang_bay = hb.ma_hang_bay
        LEFT JOIN sanbay sb_di ON cb.ma_san_bay_di = sb_di.ma_san_bay
        LEFT JOIN sanbay sb_den ON cb.ma_san_bay_den = sb_den.ma_san_bay
        WHERE v.ma_ve IS NOT NULL
        ORDER BY v.gia_ve ASC, cb.thoi_gian_di ASC
        """

        df_result = spark.sql(query)
        result = df_result.toPandas().to_dict(orient="records")

        print(f"‚úÖ L·∫•y danh s√°ch v√© th√†nh c√¥ng t·ª´ cache: {len(result)} records")
        return JSONResponse(content=result)

    except Exception as e:
        print(f"‚ùå L·ªói trong get_all_ve: {repr(e)}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


@router.get("/search-ve", tags=["ve"])
def search_ve(
    from_airport: str,
    to_airport: str,
    ten_hang_ve: str,
    departure_date: Optional[str] = None,
    max_price: Optional[float] = None,
):
    try:
        if not from_airport or not to_airport or not ten_hang_ve:
            raise HTTPException(status_code=400, detail="Thi·∫øu th√¥ng tin t√¨m ki·∫øm")

        spark = get_spark()
        spark.conf.set("spark.sql.execution.arrow.pyspark.fallback.enabled", "true")
        spark.conf.set(
            "spark.sql.autoBroadcastJoinThreshold", "-1"
        )  # t·∫Øt auto broadcast

        # C√°c b·∫£ng nh·ªè c·∫ßn broadcast
        broadcast_tables = ["hangve", "hangbanve", "hangbay", "sanbay"]
        for tbl in broadcast_tables:
            df = load_df(tbl).persist(StorageLevel.MEMORY_AND_DISK).hint("broadcast")
            df.createOrReplaceTempView(tbl)

        # C√°c b·∫£ng l·ªõn kh√¥ng broadcast
        for tbl in ["ve", "chuyenbay"]:
            load_df(tbl).persist(StorageLevel.MEMORY_AND_DISK).createOrReplaceTempView(
                tbl
            )

        conditions = [
            f"cb.ma_san_bay_di = '{safe_escape_sql(from_airport.strip())}'",
            f"cb.ma_san_bay_den = '{safe_escape_sql(to_airport.strip())}'",
            f"hv.ten_hang_ve = '{safe_escape_sql(ten_hang_ve.strip())}'",
            "v.ma_ve IS NOT NULL",
        ]

        if departure_date:
            conditions.append(
                f"DATE(cb.thoi_gian_di) = '{safe_escape_sql(departure_date)}'"
            )

        if max_price and max_price > 0:
            conditions.append(f"v.gia_ve <= {max_price}")

        where_clause = " AND ".join(conditions)

        query = f"""
        SELECT /*+ BROADCAST(hv), BROADCAST(hbv), BROADCAST(hb), BROADCAST(sb_di), BROADCAST(sb_den) */
            v.ma_ve,
            v.gia_ve,
            v.ma_chuyen_bay,
            v.ma_hang_ve,
            v.ma_hang_ban_ve,
            CAST(cb.thoi_gian_di AS STRING) AS thoi_gian_di,
            CAST(cb.thoi_gian_den AS STRING) AS thoi_gian_den,
            cb.ma_hang_bay,
            cb.ma_san_bay_di,
            cb.ma_san_bay_den,
            sb_di.ten_san_bay AS ten_san_bay_di,
            sb_den.ten_san_bay AS ten_san_bay_den,
            sb_di.thanh_pho AS ten_thanh_pho_di,
            sb_den.thanh_pho AS ten_thanh_pho_den,
            hv.ten_hang_ve,
            hv.so_kg_hanh_ly_ky_gui,
            hv.so_kg_hanh_ly_xach_tay,
            hv.so_do_ghe,
            hv.khoang_cach_ghe,
            hv.refundable,
            hv.changeable,
            hbv.ten_hang_ban_ve,
            hbv.vai_tro,
            hb.ten_hang_bay,
            hb.iata_code as hang_bay_iata,
            hb.quoc_gia,
            CONCAT(sb_di.thanh_pho, ' ‚Üí ', sb_den.thanh_pho) AS route_display,
            CONCAT(hb.ten_hang_bay, ' - ', cb.ma_chuyen_bay) AS flight_display
        FROM ve v
        LEFT JOIN chuyenbay cb ON v.ma_chuyen_bay = cb.ma_chuyen_bay
        LEFT JOIN hangve hv ON v.ma_hang_ve = hv.ma_hang_ve
        LEFT JOIN hangbanve hbv ON v.ma_hang_ban_ve = hbv.ma_hang_ban_ve
        LEFT JOIN hangbay hb ON cb.ma_hang_bay = hb.ma_hang_bay
        LEFT JOIN sanbay sb_di ON cb.ma_san_bay_di = sb_di.ma_san_bay
        LEFT JOIN sanbay sb_den ON cb.ma_san_bay_den = sb_den.ma_san_bay
        WHERE {where_clause}
        ORDER BY v.gia_ve ASC, cb.thoi_gian_di ASC
        """

        df_result = spark.sql(query)
        result = df_result.toPandas().to_dict(orient="records")
        print(
            f"üîç T√¨m ki·∫øm v√© {from_airport} ‚Üí {to_airport}, {ten_hang_ve}: {len(result)} k·∫øt qu·∫£"
        )
        return JSONResponse(content=result)

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå L·ªói trong search_ve: {repr(e)}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


@router.post("/chi-tiet-ve-nhieu", tags=["ve"])
def chi_tiet_ve_nhieu(body: GiaVeRequest):
    try:
        if (
            not body
            or not isinstance(body.ma_gia_ves, list)
            or len(body.ma_gia_ves) == 0
        ):
            raise HTTPException(status_code=400, detail="Danh s√°ch m√£ v√© kh√¥ng h·ª£p l·ªá")
        if len(body.ma_gia_ves) > 100:
            raise HTTPException(
                status_code=400, detail="Ch·ªâ cho ph√©p t·ªëi ƒëa 100 m√£ v√© m·ªói l·∫ßn"
            )

        ma_ves = [ma.strip() for ma in body.ma_gia_ves if ma.strip()]
        print(f"üì• Nh·∫≠n ma_ves ({len(ma_ves)}): {ma_ves}")

        spark = get_spark()
        spark.conf.set("spark.sql.execution.arrow.pyspark.fallback.enabled", "true")
        spark.conf.set(
            "spark.sql.autoBroadcastJoinThreshold", "-1"
        )  # T·∫Øt auto broadcast

        # Broadcast c√°c b·∫£ng nh·ªè
        for tbl in ["hangve", "hangbanve", "hangbay"]:
            df = load_df(tbl).persist(StorageLevel.MEMORY_AND_DISK).hint("broadcast")
            df.createOrReplaceTempView(tbl)

        # B·∫£ng l·ªõn kh√¥ng broadcast
        for tbl in ["ve", "chuyenbay"]:
            load_df(tbl).persist(StorageLevel.MEMORY_AND_DISK).createOrReplaceTempView(
                tbl
            )

        # X√¢y WHERE IN an to√†n
        escaped_codes = [f"'{safe_escape_sql(ma)}'" for ma in ma_ves]
        in_clause = ",".join(escaped_codes)

        query = f"""
        SELECT 
            v.ma_ve,
            v.gia_ve,
            v.ma_chuyen_bay,
            v.ma_hang_ve,
            v.ma_hang_ban_ve,
            hv.so_kg_hanh_ly_ky_gui,
            hv.so_kg_hanh_ly_xach_tay,
            hv.refundable,
            hv.changeable,
            hv.ten_hang_ve,
            hbv.ten_hang_ban_ve,
            hb.ten_hang_bay,
            cb.ma_hang_bay,
            CAST(cb.thoi_gian_di AS STRING) AS thoi_gian_di,
            CAST(cb.thoi_gian_den AS STRING) AS thoi_gian_den
        FROM ve v
        LEFT JOIN hangve hv ON v.ma_hang_ve = hv.ma_hang_ve
        LEFT JOIN hangbanve hbv ON v.ma_hang_ban_ve = hbv.ma_hang_ban_ve
        LEFT JOIN chuyenbay cb ON v.ma_chuyen_bay = cb.ma_chuyen_bay
        LEFT JOIN hangbay hb ON cb.ma_hang_bay = hb.ma_hang_bay
        WHERE v.ma_ve IN ({in_clause})
        ORDER BY v.gia_ve ASC
        """

        df_result = spark.sql(query)
        result = df_result.toPandas().to_dict(orient="records")

        print(f"‚úÖ L·∫•y chi ti·∫øt {len(result)} v√© th√†nh c√¥ng t·ª´ cache")
        return JSONResponse(content=result)

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå L·ªói trong chi_tiet_ve_nhieu: {repr(e)}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


@router.get("/{ma_gia_ve}", tags=["gia_ve"])
def get_gia_ve_day_du(ma_gia_ve: str):
    """Get detailed ticket price information by ID - supports pattern matching with optimized Spark broadcast"""
    try:
        if not ma_gia_ve or not ma_gia_ve.strip():
            raise HTTPException(status_code=400, detail="M√£ gi√° v√© kh√¥ng h·ª£p l·ªá")

        safe_ma_gia_ve = safe_escape_sql(ma_gia_ve.strip())

        spark = get_spark()
        spark.conf.set("spark.sql.execution.arrow.pyspark.fallback.enabled", "true")
        spark.conf.set(
            "spark.sql.autoBroadcastJoinThreshold", "-1"
        )  # T·∫Øt t·ª± ƒë·ªông broadcast

        # ‚úÖ Broadcast c√°c b·∫£ng nh·ªè
        for tbl in ["hangve", "hangbanve", "hangbay", "sanbay"]:
            df = load_df(tbl).hint("broadcast")
            df.createOrReplaceTempView(tbl)

        # ‚úÖ Persist b·∫£ng l·ªõn h∆°n
        for tbl in ["ve", "chuyenbay"]:
            load_df(tbl).persist().createOrReplaceTempView(tbl)

        query = f"""
        SELECT 
            v.ma_ve,
            v.gia_ve,
            v.ma_chuyen_bay,
            v.ma_hang_ve,
            v.ma_hang_ban_ve,
            CAST(cb.thoi_gian_di AS STRING) AS thoi_gian_di,
            CAST(cb.thoi_gian_den AS STRING) AS thoi_gian_den,
            cb.ma_hang_bay,
            cb.ma_san_bay_di,
            cb.ma_san_bay_den,
            sb_di.ten_san_bay AS ten_san_bay_di,
            sb_den.ten_san_bay AS ten_san_bay_den,
            sb_di.thanh_pho AS ten_thanh_pho_di,
            sb_den.thanh_pho AS ten_thanh_pho_den,
            sb_di.ma_san_bay AS ma_san_bay_di_full,
            sb_den.ma_san_bay AS ma_san_bay_den_full,
            sb_di.iata_code AS iata_code_di,
            sb_den.iata_code AS iata_code_den,
            sb_di.ma_quoc_gia AS ma_quoc_gia_di,
            sb_den.ma_quoc_gia AS ma_quoc_gia_den,
            hv.ten_hang_ve,
            hv.so_kg_hanh_ly_ky_gui,
            hv.so_kg_hanh_ly_xach_tay,
            hv.so_do_ghe,
            hv.khoang_cach_ghe,
            hv.refundable,
            hv.changeable,
            hbv.ten_hang_ban_ve,
            hbv.vai_tro,
            hb.ten_hang_bay,
            hb.iata_code AS hang_bay_iata,
            hb.quoc_gia,
            CONCAT(sb_di.thanh_pho, ' ‚Üí ', sb_den.thanh_pho) AS route_display,
            CONCAT(hb.ten_hang_bay, ' - ', cb.ma_chuyen_bay) AS flight_display,
            CONCAT(hv.ten_hang_ve) AS package_display
        FROM ve v
        LEFT JOIN chuyenbay cb ON v.ma_chuyen_bay = cb.ma_chuyen_bay
        LEFT JOIN hangve hv ON v.ma_hang_ve = hv.ma_hang_ve
        LEFT JOIN hangbanve hbv ON v.ma_hang_ban_ve = hbv.ma_hang_ban_ve
        LEFT JOIN hangbay hb ON cb.ma_hang_bay = hb.ma_hang_bay
        LEFT JOIN sanbay sb_di ON cb.ma_san_bay_di = sb_di.ma_san_bay
        LEFT JOIN sanbay sb_den ON cb.ma_san_bay_den = sb_den.ma_san_bay
        WHERE (v.ma_ve = '{safe_ma_gia_ve}' OR v.ma_ve LIKE '{safe_ma_gia_ve}+%')
        ORDER BY v.ma_ve ASC
        """

        print(f"üîç Executing query for ma_ve pattern: {safe_ma_gia_ve}")
        df_result = spark.sql(query)
        result = df_result.toPandas().to_dict(orient="records")

        if not result:
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y v√© v·ªõi m√£: {safe_ma_gia_ve}")
            raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y th√¥ng tin v√©")

        print(
            f"‚úÖ L·∫•y chi ti·∫øt v√© th√†nh c√¥ng: {safe_ma_gia_ve} - Found {len(result)} records"
        )

        return JSONResponse(content=result[0] if len(result) == 1 else result)

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå L·ªói trong get_gia_ve_day_du: {repr(e)}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


# @router.put("/{ma_gia_ve}", tags=["gia_ve"])
# def update_gia_ve(ma_gia_ve: str, gia_ve: Ve):
#     """Update ticket price with validation"""
#     try:
#         print(f"üîÑ C·∫≠p nh·∫≠t gi√° v√©: {ma_gia_ve}")

#         # Check if ticket price exists
#         if not check_exists_optimized("gia_ve", "ma_gia_ve", ma_gia_ve):
#             raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y gi√° v√©")

#         # Input validation
#         if gia_ve.gia <= 0:
#             raise HTTPException(status_code=400, detail="Gi√° v√© ph·∫£i l·ªõn h∆°n 0")

#         # Update document
#         update_data = gia_ve.dict()
#         update_data["ma_gia_ve"] = ma_gia_ve

#         result = gia_ve_collection.update_one(
#             {"ma_gia_ve": ma_gia_ve}, {"$set": update_data}
#         )

#         if result.matched_count == 0:
#             raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y gi√° v√©")

#         # Invalidate cache
#         invalidate_cache("gia_ve")

#         print(f"‚úÖ C·∫≠p nh·∫≠t gi√° v√© th√†nh c√¥ng: {ma_gia_ve}")
#         return JSONResponse(content={"message": "C·∫≠p nh·∫≠t gi√° v√© th√†nh c√¥ng"})

#     except HTTPException:
#         raise
#     except Exception as e:
#         print(f"‚ùå L·ªói trong update_gia_ve: {repr(e)}")
#         traceback.print_exc()
#         raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


@router.delete("/{ma_gia_ve}", tags=["gia_ve"])
def delete_gia_ve(ma_gia_ve: str):
    """Delete ticket price with validation"""
    try:
        print(f"üóë Nh·∫≠n y√™u c·∫ßu x√≥a gi√° v√©: {ma_gia_ve}")

        # Check if ticket price exists
        if not check_exists_optimized("gia_ve", "ma_gia_ve", ma_gia_ve):
            raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y gi√° v√©")

        # Delete document
        result = gia_ve_collection.delete_one({"ma_gia_ve": ma_gia_ve})

        if result.deleted_count == 0:
            raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y gi√° v√©")

        # Invalidate cache
        invalidate_cache("gia_ve")

        print(f"‚úÖ X√≥a gi√° v√© th√†nh c√¥ng: {ma_gia_ve}")
        return JSONResponse(content={"message": f"X√≥a gi√° v√© {ma_gia_ve} th√†nh c√¥ng"})

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå L·ªói trong delete_gia_ve: {repr(e)}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail="L·ªói server n·ªôi b·ªô")


@router.get("/stats/summary", tags=["gia_ve"])
def get_gia_ve_stats():
    """Get ticket price statistics using Spark SQL"""
    try:
        spark = get_spark()
        validate_required_views()

        query = """
        SELECT 
            COUNT(*) as total_prices,
            MIN(gv.gia) as min_price,
            MAX(gv.gia) as max_price,
            AVG(gv.gia) as avg_price,
            COUNT(DISTINCT gv.ma_chuyen_bay) as unique_flights,
            COUNT(DISTINCT gv.ma_hang_ve) as unique_classes,
            COUNT(DISTINCT cb.ma_hang_bay) as unique_airlines
        FROM gia_ve gv
        LEFT JOIN chuyen_bay cb ON gv.ma_chuyen_bay = cb.ma_chuyen_bay
        WHERE gv.ma_gia_ve IS NOT NULL
        """

        df_stats = spark.sql(query)
        stats = df_stats.collect()[0].asDict()

        return JSONResponse(content=stats)

    except Exception as e:
        print(f"‚ùå L·ªói l·∫•y th·ªëng k√™: {repr(e)}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail="L·ªói l·∫•y th·ªëng k√™ gi√° v√©")


@router.post("/import-excel", tags=["ve"])
async def import_ve_from_excel(file: UploadFile = File(...)):
    """Import tickets from Excel file - SIMPLIFIED"""
    try:
        # üî• Validate file type
        if not file.filename.endswith((".xlsx", ".xls")):
            raise HTTPException(
                status_code=400, detail="Ch·ªâ ch·∫•p nh·∫≠n file Excel (.xlsx, .xls)"
            )

        print(f"üì• Import Excel file: {file.filename}")

        # üî• Read Excel
        contents = await file.read()
        df = pd.read_excel(io.BytesIO(contents))

        print(f"üìä Excel columns: {df.columns.tolist()}")
        print(f"üìä Excel rows: {len(df)}")

        # üî• FLEXIBLE column mapping - accept different column names
        column_mappings = {
            "ma_ve": ["ma_ve", "Ma_ve", "MA_VE", "mave", "ticket_id", "ticket_code"],
            "gia_ve": ["gia_ve", "Gia_ve", "GIA_VE", "giave", "price", "gia"],
            "ma_hang_ve": [
                "ma_hang_ve",
                "Ma_hang_ve",
                "MA_HANG_VE",
                "mahangve",
                "class_code",
                "hang_ve",
            ],
            "ma_chuyen_bay": [
                "ma_chuyen_bay",
                "Ma_chuyen_bay",
                "MA_CHUYEN_BAY",
                "machuyenbay",
                "flight_code",
                "chuyen_bay",
            ],
            "ma_hang_ban_ve": [
                "ma_hang_ban_ve",
                "Ma_hang_ban_ve",
                "MA_HANG_BAN_VE",
                "mahangbanve",
                "seller_code",
                "hang_ban_ve",
            ],
        }

        # üî• Auto-detect columns
        detected_columns = {}
        for standard_name, possible_names in column_mappings.items():
            found = False
            for possible in possible_names:
                if possible in df.columns:
                    detected_columns[standard_name] = possible
                    found = True
                    break
            if not found:
                print(f"‚ö†Ô∏è Column '{standard_name}' not found, will use default")

        print(f"üîç Detected columns: {detected_columns}")

        # üî• Rename columns to standard names
        df_renamed = df.copy()
        for standard, detected in detected_columns.items():
            if detected in df_renamed.columns:
                df_renamed = df_renamed.rename(columns={detected: standard})

        # üî• Keep only required columns that exist
        required_columns = [
            "ma_ve",
            "gia_ve",
            "ma_hang_ve",
            "ma_chuyen_bay",
            "ma_hang_ban_ve",
        ]
        available_columns = [
            col for col in required_columns if col in df_renamed.columns
        ]

        if not available_columns:
            raise HTTPException(
                status_code=400,
                detail=f"Kh√¥ng t√¨m th·∫•y c·ªôt n√†o trong s·ªë: {required_columns}. Available: {df.columns.tolist()}",
            )

        df_clean = df_renamed[available_columns].copy()

        # üî• Drop rows with missing critical data
        df_clean = df_clean.dropna(
            subset=["ma_ve"] if "ma_ve" in df_clean.columns else available_columns[:1]
        )

        if df_clean.empty:
            raise HTTPException(status_code=400, detail="File kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá")

        print(f"üìã Clean data shape: {df_clean.shape}")
        print(f"üìã Sample data:\n{df_clean.head()}")

        # üî• Process each row - MINIMAL validation
        success_count = 0
        error_count = 0
        errors = []

        # Get existing ma_ve to avoid duplicates
        existing_ma_ves = set()
        try:
            existing_docs = ve_collection.find({}, {"ma_ve": 1})
            existing_ma_ves = {doc["ma_ve"] for doc in existing_docs if "ma_ve" in doc}
            print(f"üìù Found {len(existing_ma_ves)} existing tickets")
        except Exception as e:
            print(f"‚ö†Ô∏è Could not load existing tickets: {e}")

        for index, row in df_clean.iterrows():
            try:
                # üî• Build data dict from available columns
                ve_data = {}

                for col in available_columns:
                    value = row[col]
                    if pd.isna(value):
                        if col == "ma_ve":
                            errors.append(
                                f"D√≤ng {index + 2}: M√£ v√© kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"
                            )
                            error_count += 1
                            continue
                        ve_data[col] = ""
                    elif col == "gia_ve":
                        try:
                            ve_data[col] = float(value)
                            if ve_data[col] <= 0:
                                errors.append(
                                    f"D√≤ng {index + 2}: Gi√° v√© ph·∫£i l·ªõn h∆°n 0"
                                )
                                error_count += 1
                                continue
                        except (ValueError, TypeError):
                            errors.append(
                                f"D√≤ng {index + 2}: Gi√° v√© kh√¥ng h·ª£p l·ªá: {value}"
                            )
                            error_count += 1
                            continue
                    else:
                        ve_data[col] = str(value).strip()

                # Skip if ma_ve validation failed
                if "ma_ve" not in ve_data:
                    continue

                # üî• Check duplicate
                if ve_data["ma_ve"] in existing_ma_ves:
                    errors.append(
                        f"D√≤ng {index + 2}: M√£ v√© {ve_data['ma_ve']} ƒë√£ t·ªìn t·∫°i"
                    )
                    error_count += 1
                    continue

                # üî• Fill missing fields with defaults
                default_values = {
                    "gia_ve": 0.0,
                    "ma_hang_ve": "DEFAULT",
                    "ma_chuyen_bay": "DEFAULT",
                    "ma_hang_ban_ve": "DEFAULT",
                }

                for field, default in default_values.items():
                    if field not in ve_data:
                        ve_data[field] = default

                # üî• Insert to database
                try:
                    result = ve_collection.insert_one(ve_data)
                    if result.inserted_id:
                        success_count += 1
                        existing_ma_ves.add(
                            ve_data["ma_ve"]
                        )  # Add to set to prevent duplicates in same import
                        if success_count % 10 == 0:
                            print(f"üìà Imported {success_count} records...")
                    else:
                        errors.append(f"D√≤ng {index + 2}: Kh√¥ng th·ªÉ th√™m v√†o database")
                        error_count += 1
                except DuplicateKeyError:
                    errors.append(
                        f"D√≤ng {index + 2}: M√£ v√© {ve_data['ma_ve']} ƒë√£ t·ªìn t·∫°i"
                    )
                    error_count += 1
                except Exception as insert_err:
                    errors.append(f"D√≤ng {index + 2}: L·ªói insert: {str(insert_err)}")
                    error_count += 1

            except Exception as row_err:
                errors.append(f"D√≤ng {index + 2}: {str(row_err)}")
                error_count += 1

        # üî• Invalidate cache if successful
        if success_count > 0:
            invalidate_cache("ve")

        # üî• Result summary
        result_message = {
            "message": f"Import ho√†n t·∫•t: {success_count} th√†nh c√¥ng, {error_count} l·ªói",
            "success_count": success_count,
            "error_count": error_count,
            "errors": errors[:20] if errors else [],  # Show first 20 errors
            "total_errors": len(errors),
            "detected_columns": detected_columns,
            "processed_rows": len(df_clean),
        }

        print(f"üìä Import k·∫øt qu·∫£: {success_count} th√†nh c√¥ng, {error_count} l·ªói")

        return JSONResponse(content=result_message)

    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå L·ªói import Excel: {repr(e)}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"L·ªói x·ª≠ l√Ω file Excel: {str(e)}")


@router.patch("/fix-hang-ban-ve", tags=["ve"])
def fix_hang_ban_ve_to_default():
    """Fix t·∫•t c·∫£ ma_hang_ban_ve v·ªÅ HBV001 - EMERGENCY FIX"""
    try:
        print("üîß FIXING: Update t·∫•t c·∫£ ma_hang_ban_ve v·ªÅ HBV001...")

        # üî• UPDATE t·∫•t c·∫£ records v·ªÅ HBV001
        result = ve_collection.update_many(
            {}, {"$set": {"ma_hang_ban_ve": "HBV001"}}  # Empty filter = update ALL
        )

        print(f"‚úÖ Updated {result.modified_count} records to HBV001")

        # Invalidate cache
        invalidate_cache("ve")

        return JSONResponse(
            content={
                "message": f"‚úÖ ƒê√£ fix {result.modified_count} v√© v·ªÅ ma_hang_ban_ve = HBV001",
                "updated_count": result.modified_count,
                "fixed_value": "HBV001",
            }
        )

    except Exception as e:
        print(f"‚ùå L·ªói fix hang_ban_ve: {repr(e)}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail="L·ªói fix hang_ban_ve")
